{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# SOLUÇÃO DA LISTA 2 - Igor Faluhelyi, 180122207\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "PATH = 'C:/Users/Igor/Desktop/ce2_python'\n",
    "\n",
    "iris =  pd.read_csv(f'{PATH}/iris.data', header= None)\n",
    "iris = iris.rename(columns={0:'sepal_length', 1:'sepal_width', 2:'petal_length', 3:'petal_width', 4:'class'})\n",
    "\n",
    "def condition_class(x):\n",
    "    if x == 'Iris-setosa':\n",
    "        return 0\n",
    "    elif x == 'Iris-versicolor':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2  \n",
    "def condition_sl(x):\n",
    "    if x <= 5.100000:\n",
    "        return 0\n",
    "    elif x <= 5.800000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2   \n",
    "def condition_sw(x):\n",
    "    if x <= 2.800000:\n",
    "        return 0\n",
    "    elif x <= 3.000000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "def condition_pl(x):\n",
    "    if x <= 1.600000:\n",
    "        return 0\n",
    "    elif x <= 4.350000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2   \n",
    "def condition_pw(x):\n",
    "    if x <= 0.300000:\n",
    "        return 0\n",
    "    elif x <= 1.300000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "iris['class_'] = iris.iloc[:, -1].apply(condition_class)\n",
    "iris['index'] = iris.index\n",
    "\n",
    "iris['sepal_length_'] = iris.iloc[:, 0].apply(condition_sl)\n",
    "iris['sepal_width_'] = iris.iloc[:, 1].apply(condition_sw)\n",
    "iris['petal_length_'] = iris.iloc[:, 2].apply(condition_pl)\n",
    "iris['petal_width_'] = iris.iloc[:, 3].apply(condition_pw)\n",
    "\n",
    "iris_ = iris[['sepal_length_', 'sepal_width_', 'petal_length_', 'petal_width_', 'class_', 'index']]\n",
    "\n",
    "iris_test_ = iris_.sample(n = 60, random_state=3, replace = False)\n",
    "iris_train_ = iris_[~iris_['index'].isin(iris_.sample(n = 60, random_state=3, replace = False)['index'].values)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um nó (classificação usando 1 variavel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= np.array(iris_train_.groupby('class_')['index'].agg('count'))/len(iris_train_)\n",
    "B = np.log10(np.array(iris_train_.groupby('class_')['index'].agg('count'))/len(iris_train_)).transpose()\n",
    "\n",
    "H_t = -1*(np.matmul(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganho_info = []\n",
    "for column in iris_train_.columns[0:-2]:\n",
    "    a = iris_train_.groupby([column, 'class_'])['index'].agg(['count'])\n",
    "    a = a/len(iris_train_)\n",
    "    H_tc = 0\n",
    "    for i in range(len(np.unique(iris_train_[column]))):\n",
    "        H_tc += -1*(np.matmul(a.loc[i].values.transpose(), np.log10(a.loc[i].values.transpose()/sum(a.loc[i].values)).transpose()))\n",
    "    ganho_info.append(H_t - H_tc)\n",
    "\n",
    "n1 = iris_train_.columns[0:-2][np.argmax(ganho_info)]\n",
    "\n",
    "d= iris_train_.groupby([n1, 'class_'])['index'].agg(['count'])/len(iris_train_)\n",
    "\n",
    "dd = {}\n",
    "for i in d.index:\n",
    "    dd[i[0]] = d.loc[i[0]].index[np.argmax(d.loc[i[0]])]\n",
    "\n",
    "def decision(x):\n",
    "    if (x) in dd.keys():\n",
    "        return dd[(x)]\n",
    "    else:\n",
    "        rng = np.random.RandomState(3)\n",
    "        return rng.choice(list(dd.values()))\n",
    "\n",
    "\n",
    "result1_train = list(map(decision, iris_train_[n1]))\n",
    "\n",
    "accuracy1_train = (result1_train==iris_train_['class_'].values).sum()/len(result1_train)\n",
    "\n",
    "\n",
    "result1_test = list(map(decision, iris_test_[n1]))\n",
    "\n",
    "accuracy1_test = (result1_test==iris_test_['class_'].values).sum()/len(result1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no treinamento: 0.8222222222222222\n",
      " Acurácia no teste: 0.75\n"
     ]
    }
   ],
   "source": [
    "print(f'Acurácia no treinamento: {accuracy1_train}\\n Acurácia no teste: {accuracy1_test}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dois nós (classificação usando 2 variaveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= np.array(iris_train_.groupby([n1, 'class_'])['index'].agg('count'))/len(iris_train_)\n",
    "B = np.log10(np.array(iris_train_.groupby([n1, 'class_'])['index'].agg('count'))/len(iris_train_)).transpose()\n",
    "\n",
    "H_t = -1*(np.matmul(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganho_info = []\n",
    "for column in pd.DataFrame(iris_train_.columns[0:-2])[~iris_train_.columns[0:-2].isin([n1])].values:\n",
    "    a = iris_train_.groupby([n1, column[0], 'class_'])['index'].agg(['count'])\n",
    "    a = a/len(iris_train_)\n",
    "    H_tc = 0\n",
    "    for i in a.index:\n",
    "        H_tc += -1*(np.matmul(a.loc[i].values.transpose(), np.log10(a.loc[i].values.transpose()/sum(a.loc[i[0:-1]].values)).transpose()))\n",
    "    ganho_info.append(H_t - H_tc)\n",
    "\n",
    "n2 = pd.DataFrame(iris_train_.columns[0:-2])[~iris_train_.columns[0:-2].isin([n1])].values[np.argmax(ganho_info)][0]\n",
    "\n",
    "d= iris_train_.groupby([n1, n2, 'class_'])['index'].agg(['count'])/len(iris_train_)\n",
    "\n",
    "dd = {}\n",
    "for i in d.index:\n",
    "    #print(i[0:2], d.loc[i[0:2]].index[np.argmax(d.loc[i[0:2]])])\n",
    "    dd[i[0:2]] = d.loc[i[0:2]].index[np.argmax(d.loc[i[0:2]])]\n",
    "\n",
    "def decision(x, y):\n",
    "    if (x, y) in dd.keys():\n",
    "        return dd[(x, y)]\n",
    "    else:\n",
    "        rng = np.random.RandomState(3)\n",
    "        return rng.choice(list(dd.values()))\n",
    "\n",
    "\n",
    "result2_train = list(map(decision, iris_train_[n1], iris_train_[n2]))\n",
    "\n",
    "accuracy2_train = (result2_train==iris_train_['class_'].values).sum()/len(result2_train)\n",
    "\n",
    "\n",
    "result2_test = list(map(decision, iris_test_[n1], iris_test_[n2]))\n",
    "\n",
    "accuracy2_test = (result2_test==iris_test_['class_'].values).sum()/len(result2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no treinamento: 0.8777777777777778\n",
      " Acurácia no teste: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(f'Acurácia no treinamento: {accuracy2_train}\\n Acurácia no teste: {accuracy2_test}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Três nós (classificação usando 3 variaveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= np.array(iris_train_.groupby([n1, n2, 'class_'])['index'].agg('count'))/len(iris_train_)\n",
    "B = np.log10(np.array(iris_train_.groupby([n1, n2, 'class_'])['index'].agg('count'))/len(iris_train_)).transpose()\n",
    "\n",
    "H_t = -1*(np.matmul(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganho_info = []\n",
    "for column in pd.DataFrame(iris_train_.columns[0:-2])[~iris_train_.columns[0:-2].isin([n1, n2])].values:\n",
    "    a = iris_train_.groupby([n1, n2, column[0], 'class_'])['index'].agg(['count'])\n",
    "    a = a/len(iris_train_)\n",
    "    H_tc = 0\n",
    "    for i in a.index:\n",
    "        H_tc += -1*(np.matmul(a.loc[i].values.transpose(), np.log10(a.loc[i].values.transpose()/sum(a.loc[i[0:-1]].values)).transpose()))\n",
    "    ganho_info.append(H_t - H_tc)\n",
    "\n",
    "n3 = pd.DataFrame(iris_train_.columns[0:-2])[~iris_train_.columns[0:-2].isin([n1, n2])].values[np.argmax(ganho_info)][0]\n",
    "\n",
    "d= iris_train_.groupby([n1, n2, n3, 'class_'])['index'].agg(['count'])/len(iris_train_)\n",
    "\n",
    "dd = {}\n",
    "for i in d.index:\n",
    "    dd[i[0:3]] = d.loc[i[0:3]].index[np.argmax(d.loc[i[0:3]])]\n",
    "\n",
    "def decision(x, y, z):\n",
    "    if (x, y, z) in dd.keys():\n",
    "        return dd[(x, y, z)]\n",
    "    else:\n",
    "        rng = np.random.RandomState(3)\n",
    "        return rng.choice(list(dd.values()))\n",
    "    \n",
    "\n",
    "result3_train = list(map(decision, iris_train_[n1], iris_train_[n2], iris_train_[n3]))\n",
    "\n",
    "accuracy3_train = (result3_train==iris_train_['class_'].values).sum()/len(result3_train)\n",
    "\n",
    "\n",
    "result3_test = list(map(decision, iris_test_[n1], iris_test_[n2], iris_test_[n3]))\n",
    "\n",
    "accuracy3_test = (result3_test==iris_test_['class_'].values).sum()/len(result3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no treinamento: 0.8888888888888888\n",
      " Acurácia no teste: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(f'Acurácia no treinamento: {accuracy3_train}\\n Acurácia no teste: {accuracy3_test}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quatro nós (classificação usando 4 variaveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= np.array(iris_train_.groupby([n1, n2, n3, 'class_'])['index'].agg('count'))/len(iris_train_)\n",
    "B = np.log10(np.array(iris_train_.groupby([n1, n2, n3, 'class_'])['index'].agg('count'))/len(iris_train_)).transpose()\n",
    "\n",
    "H_t = -1*(np.matmul(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganho_info = []\n",
    "for column in pd.DataFrame(iris_train_.columns[0:-2])[~iris_train_.columns[0:-2].isin([n1, n2, n3])].values:\n",
    "    a = iris_train_.groupby([n1, n2, n3, column[0], 'class_'])['index'].agg(['count'])\n",
    "    a = a/len(iris_train_)\n",
    "    H_tc = 0\n",
    "    for i in a.index:\n",
    "        H_tc += -1*(np.matmul(a.loc[i].values.transpose(), np.log10(a.loc[i].values.transpose()/sum(a.loc[i[0:-1]].values)).transpose()))\n",
    "    ganho_info.append(H_t - H_tc)\n",
    "\n",
    "n4 = pd.DataFrame(iris_train_.columns[0:-2])[~iris_train_.columns[0:-2].isin([n1, n2, n3])].values[np.argmax(ganho_info)][0]\n",
    "\n",
    "d= iris_train_.groupby([n1, n2, n3, n4, 'class_'])['index'].agg(['count'])/len(iris_train_)\n",
    "\n",
    "dd = {}\n",
    "for i in d.index:\n",
    "    dd[i[0:4]] = d.loc[i[0:4]].index[np.argmax(d.loc[i[0:4]])]\n",
    "\n",
    "def decision(x, y, z, w):\n",
    "    if (x, y, z, w) in dd.keys():\n",
    "        return dd[(x, y, z, w)]\n",
    "    else:\n",
    "        rng = np.random.RandomState(3)\n",
    "        return rng.choice(list(dd.values()))\n",
    "    \n",
    "\n",
    "result4_train = list(map(decision, iris_train_[n1], iris_train_[n2], iris_train_[n3], iris_train_[n4]))\n",
    "\n",
    "accuracy4_train = (result4_train==iris_train_['class_'].values).sum()/len(result4_train)\n",
    "\n",
    "\n",
    "result4_test = list(map(decision, iris_test_[n1], iris_test_[n2], iris_test_[n3], iris_train_[n4]))\n",
    "\n",
    "accuracy4_test = (result4_test==iris_test_['class_'].values).sum()/len(result4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no treinamento: 0.9\n",
      " Acurácia no teste: 0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f'Acurácia no treinamento: {accuracy4_train}\\n Acurácia no teste: {accuracy4_test}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações finais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As melhores classificações nos dados de teste vieram das árvores de decisão com 2 e 3 nós. Apenas 1 nó não foi suficiente para distinguir o tipo da flor e com 4 nós, o algorítmo CART sofreu Overfitting, já que observamos ajuste muito bem aos dados de treinamento (90% de acerto) e péssimo resultado nos dados de teste quando comparado às outras àrvores de decisão (com menos variáveis).\n",
    "\n",
    "- A árvore com 2 nós obteve melhores resultados, já que obteve acurácia nos dados de teste igual à arvore com 3 nós e venceu no critério de parcimônia. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
